{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80eb4366-bc44-4666-b526-721410e835d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7b371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folders and file paths\n",
    "papers_folder = 'F:/OAGProject/OAGFiles/OAGPublications'\n",
    "output_folder = 'F:/OAGProject/Output'\n",
    "references_folder = '/users/PGS0283/jhoope11/jack/Graphs/UpdatedFiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364385d-b6db-44c3-a5bf-ec890856096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_papers(file_path):\n",
    "    print(f\"Reading papers from file: {file_path}\\n\")\n",
    "    papers = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            paper_data = json.loads(line.strip())  # Parse each line as JSON\n",
    "            paper_id = paper_data.get(\"id\")\n",
    "            if not paper_id:\n",
    "                continue  # Skip this line if id is missing\n",
    "            title = paper_data.get(\"title\", \"\")\n",
    "            year = paper_data.get(\"year\", \"\")\n",
    "            venue_name = paper_data.get(\"venue\", \"\")\n",
    "            n_citation = paper_data.get(\"n_citation\", \"\")\n",
    "            authors = [{\"Name\": author.get(\"name\", \"\"), \"AuthorId\": author.get(\"id\", \"\"), \"AuthorOrg\": author.get(\"org\", \"\")} for author in paper_data.get(\"authors\", [])]\n",
    "            num_authors = len(authors)\n",
    "            keywords = paper_data.get(\"keywords\", \"\")\n",
    "            abstracts = paper_data.get(\"abstract\", \"\")\n",
    "            #fos = [field.get(\"name\", \"\") for field in paper_data.get(\"fos\", [])]\n",
    "            papers[paper_id] = {\n",
    "                \"Title\": title,\n",
    "                \"authors\": authors,\n",
    "                \"Year\": year,\n",
    "                \"Venue\": venue_name,\n",
    "                \"NumCitations\": n_citation,\n",
    "                \"NumAuthors\": num_authors,\n",
    "                \"Authors\": authors,\n",
    "                \"Keywords\": keywords,\n",
    "                \"Abstracts\": abstracts\n",
    "            }\n",
    "    print(\"Papers read.\\n\")\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ba333-9c31-49b3-a117-6c2d070bb3c5",
   "metadata": {},
   "source": [
    "Need to break up the create_json_file function so the reference file can be made in its own function that is called on instead of at the end of the current function to attempt to fix the issue of only the last file be added to reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c272be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_file(output_folder, paper_id_mapping):\n",
    "    reference_file_path = os.path.join(output_folder, \"reference.json\")\n",
    "    with open(reference_file_path, 'w') as rf:\n",
    "        json.dump(paper_id_mapping, rf, indent=4)\n",
    "    print(f\"Reference file created: {reference_file_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dcb8839-b61f-4f8f-9e8c-1db8290c8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(output_folder, papers, master_file_name):\n",
    "    print(f\"Creating JSON files in folder: {output_folder}\\n\")\n",
    "    count = 0\n",
    "    file_count = 0\n",
    "    paper_id_mapping = {}\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    output_file = os.path.join(output_folder, f\"papers_chunk_{file_count}.json\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"[\")\n",
    "        for paper_id, paper_info in papers.items():\n",
    "            if count == 2000:\n",
    "                f.write(\"\\n]\")\n",
    "                f.close()\n",
    "                # Map the current chunk to its corresponding file\n",
    "                paper_id_mapping.update({pid: f\"papers_chunk_{file_count}.json\" for pid in papers.keys()})\n",
    "                \n",
    "                # Start a new chunk\n",
    "                count = 0\n",
    "                file_count += 1\n",
    "                output_file = os.path.join(output_folder, f\"papers_chunk_{file_count}.json\")\n",
    "                f = open(output_file, 'w')\n",
    "                f.write(\"[\")\n",
    "            if count != 0:\n",
    "                f.write(\",\\n\")\n",
    "            f.write(json.dumps({\n",
    "                'PaperId': paper_id,\n",
    "                'PaperTitle': paper_info['Title'],\n",
    "                'MasterFileName': master_file_name,\n",
    "                'Journal': paper_info['Venue'],\n",
    "                'Year': paper_info['Year'],\n",
    "                'NumAuthors': paper_info['NumAuthors'],\n",
    "                'Authors': paper_info['Authors']\n",
    "            }))\n",
    "            count += 1\n",
    "        f.write(\"\\n]\")\n",
    "    \n",
    "    # Finalize mapping for the last chunk\n",
    "    paper_id_mapping.update({pid: f\"papers_chunk_{file_count}.json\" for pid in papers.keys()})\n",
    "\n",
    "    # Call function to create reference file\n",
    "    create_reference_file(output_folder, paper_id_mapping)\n",
    "\n",
    "    print(f\"JSON files created in folder: {output_folder}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af614af-9b71-43d8-a32c-fb505adb54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_papers(i, papers_folder):\n",
    "    print(f\"Processing papers file {i}\\n\")\n",
    "    papers_file = os.path.join(papers_folder, f\"v3.1_oag_publication_{i}.json\")\n",
    "    papers = read_papers(papers_file)\n",
    "\n",
    "    # for j in range(5):  # Assuming authors files are named mag_authors_0.txt to mag_authors_4.txt\n",
    "    #     print(f\"Processing authors file {j} for papers file {i}\\n\")\n",
    "    #     #authors_file = os.path.join(authors_folder, f\"mag_authors_{j}.txt\")\n",
    "    #     #read_authors(authors_file, affiliations, papers)\n",
    "\n",
    "    output_file = os.path.join(output_folder, f\"papers_chunk_{i}.json\")\n",
    "    create_json_file(output_file, papers, f\"v3.1_oag_publication_{i}.json\")\n",
    "    print(f\"Chunk {i} processing complete\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd02695-6b0e-419d-8fe7-0b5e01fc2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(papers_folder, output_folder):\n",
    "    print(\"Processing files...\\n\")\n",
    "    \n",
    "    # with Pool(processes=28) as pool:\n",
    "    #     pool.starmap(process_papers, [(i, papers_folder) for i in range(5)])\n",
    "    # pool.close()\n",
    "    # pool.join()\n",
    "    process_papers(1, papers_folder)\n",
    "    print(\"All files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d449726-fae3-47b0-a9f4-d8f5e9274aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files...\n",
      "\n",
      "Processing papers file 1\n",
      "\n",
      "Reading papers from file: F:/OAGProject/OAGFiles/OAGPublications\\v3.1_oag_publication_1.json\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Process all files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mprocess_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpapers_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m, in \u001b[0;36mprocess_files\u001b[1;34m(papers_folder, output_folder)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing files...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# with Pool(processes=28) as pool:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#     pool.starmap(process_papers, [(i, papers_folder) for i in range(5)])\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# pool.close()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# pool.join()\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mprocess_papers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpapers_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll files processed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mprocess_papers\u001b[1;34m(i, papers_folder)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing papers file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m papers_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(papers_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv3.1_oag_publication_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m papers \u001b[38;5;241m=\u001b[39m \u001b[43mread_papers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpapers_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# for j in range(5):  # Assuming authors files are named mag_authors_0.txt to mag_authors_4.txt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     print(f\"Processing authors file {j} for papers file {i}\\n\")\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     #authors_file = os.path.join(authors_folder, f\"mag_authors_{j}.txt\")\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#     #read_authors(authors_file, affiliations, papers)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpapers_chunk_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36mread_papers\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading papers from file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m papers \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m         paper_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line\u001b[38;5;241m.\u001b[39mstrip())\n",
      "File \u001b[1;32mc:\\Users\\jhoope11_stu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m(),\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "# Process all files\n",
    "process_files(papers_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff8a8d-5c6e-48a1-a8c7-87c846ba19ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
